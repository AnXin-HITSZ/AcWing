# 6. thrift

**目录：**

[TOC]

---

> thrift 官网：[thrift 官方网址](https://thrift.apache.org/)。

> thrift 和 Socket 相比，thrift 其优势在于写起来简单，即不需要额外实现跨语言、跨服务器的代码部分。

> 拓展：
> 
> 在 Linux 下如何测试是否联网：
> ```bash
> ping www.baidu.com
> ```
>
> 若可以 `ping` 通，则说明在当前 Linux 下已联网。

## 一、thrift 简介

在游戏服务中，至少需要维护一个匹配系统和一个数据存储系统。

游戏进程需要向匹配系统提供两个函数 `add_user` 和 `remove_user`，其中 `add_user` 用于匹配系统接收开始匹配的用户，而 `remove_user` 用于从匹配系统中移除取消匹配的用户。匹配系统需要向数据存储系统提供一个函数 `save_data`，用于向数据存储系统提供匹配成功的用户。

上述描述中，将游戏进程、匹配系统和数据存储系统抽象为三个节点，且存在两条有向边：一条为从游戏进程节点指向匹配系统节点，用于提供 `add_user` 和 `remove_user` 函数；另一条为从匹配系统节点指向数据存储节点，用于提供 `save_data` 函数。

> 注意：每条有向边都可以提供多个功能，例如从游戏进程节点指向匹配系统节点的这条有向边提供了 `add_user` 和 `remove_user` 等两个函数的功能。

因此，该游戏服务被抽象为一个有向图，而 thrift 的功能即为提供该有向图中的有向边。

thrift 也被称为 rpc 框架，即**远程函数调用框架**。

thrift 的实现主要包括以下 3 步骤：
1. 定义接口；
2. 实现 server 端；
3. 编写 client 端。

因此，本项目旨在利用 thrift 实现上述游戏服务。其中，游戏进程部署在 AC Terminal 上，采用 Python3 语言编写；匹配系统部署在 AC Terminal 上，采用 C++ 语言编写；数据存储系统部署在 myserver 上，其端口号为 9090，采用已提供好的接口，无需自行编写。

综合以上分析，我们可以得出：在游戏服务节点，需要实现 match-client 端；在匹配系统节点，需要实现 match-server 端和 save-client 端；而在数据存储系统节点，需要实现 save-server 端。

在本项目中，save-server 端已被提供，因此不需要我们自行实现，采用已提供好的接口即可。

> 注意：上述 match-client 端、match-server 端、save-client 端 和 save-server 端 被称为**微服务**。

## 二、项目实现过程

> 注意：
> * 对于工程项目而言，最好做到 0 warning。
> * 在写项目的过程中，最好将实现步骤记录并存下来，以便于下一次复现时备忘查询。（类似于动态规划为什么比暴力搜索快？是因为动态规划将过程中每一步的结果记录并存储下来！）

首先在项目的根目录 `thrift/` 下创建 3 个子目录 `match_system`、`game`、`thrift`，分别用来存放匹配系统、游戏服务、thrift 接口的实现代码。

> 注意：文件名 / 文件夹名中最好使用下划线（`_`）而非减号（`-`），否则在 Python 文件中将会把 `-` 识别为减号，从而导致导包错误等。

### 2.1 前置知识

#### 2.1.1 C++ 文件的编译

C++ 语言的 `.cpp` 文件的编译需要先后进行编译和链接两步处理后，才可以变为可执行文件。

例如，对于 `main.cpp` 文件，使用以下方式进行编译：
```bash
# 编译
g++ -c main.cpp
```

编译之后，使用以下方式进行链接：
```bash
# 链接
g++ *.o -o main -lthrift    # 加入 thrift 的动态链接库
g++ *.o -o main -lthrift -pthread   # 加入 thrift 和 线程 的动态链接库
```

#### 2.1.2 多线程与锁

##### 2.1.2.1 多线程

> 注意：多线程和多进程存在区别，是不同的概念！

Linux 系统中可以存在多个进程，每一个进程中可以开多个线程。

开多线程的开销是很小的，而开多进程的开销是很大的。

Linux 操作系统可以将不同线程分配到不同的核上执行。

C++ 中开一个线程非常容易，如下所示：
```cpp
thread 线程名(被该线程执行的函数名);
```

示例代码：
```cpp
thread matching_thread(consume_task);
```
即可创建一个名为 `matching_thread` 的线程，该线程用于执行函数 `consume_task()`。

##### 2.1.2.2 锁

提到多线程，一个绕不开的概念就是锁。

由于多个线程将会共享同一个内存空间，因此为了避免不同线程同时对同一个数据结构进行修改，需要对临界区使用锁。

操作系统为锁提供信号量这一变量。信号量存在 `P`（`P(S)` 即为 `S--`） 和 `V`(`V(s)` 即为 `S++`) 操作，均为原子操作（即 `P` 和 `V` 操作均不会被中途打断）。

互斥量（mutex）属于信号量的一种，其信号量值为 `1`（即 `mutex = 1`），即同一时间只能有一个进程进入临界区。

C++ 中锁的示例代码：
```cpp
unique_lock<mutex> lck(message_queue.m);  // 加锁

message_queue.q.push({user, "add"});   // 对数据结构进行修改操作

message_queue.cv.notify_all();   // 通知由于该锁而导致阻塞的进程可以继续执行了，即唤醒由于该锁而导致挂起的进程

lck.unlock();  // 解锁
```

由信号量引出条件变量这一概念。

C++ 中条件变量的使用示例如下所示：
```cpp
message_queue.cv.wait(lck);
```
对于上述示例代码，当锁 `lck` 满足条件时，将会释放锁 `lck`，相当于 `V` 操作。

### 2.2 thrift 接口定义

在子目录 `thrift` 下创建接口定义文件 `match.thrift`：
```thrift
namespace cpp match_service

struct User {
    1: i32 id,
    2: string name,
    3: i32 score
}

service Match {

    /**
     * user: 添加的用户信息
     * info: 附加信息
     * 在匹配池中添加一名用户
     */
    i32 add_user(1: User user, 2: string info),

    /**
     * user: 删除的用户信息
     * info: 附加信息
     * 从匹配池中删除一名用户
     */
    i32 remove_user(1: User user, 2: string info),
}
```

同样，创建接口定义文件 `save.thrift`：
```thrift
namespace cpp save_service

service Save {

    /**
     * username: myserver 的名称
     * password: myserver 的密码的 md5sum 的前 8 位
     * 用户名密码验证成功会返回 0，验证失败会返回 1
     * 验证成功后，结果会被保存到 myserver:homework/lesson_6/result.txt 中
     */
    i32 save_data(1: string username, 2: string password, 3: i32 player1_id, 4: i32 player2_id)
}
```

### 2.3 匹配系统服务端（C++）

#### 2.3.1 整体功能概览

匹配系统服务端实现了一个**用户匹配服务器**，核心功能是：
1. 通过 Thrift 对外提供 RPC 接口：
   * `add_user`：用户进入匹配池。
   * `remove_user`：用户退出匹配池。
2. 内部维护一个匹配池（`Pool`）：
   * 保存等待匹配的用户；
   * 根据分数差和等待时间动态扩大匹配范围；
   * 一旦匹配成功，就调用另一个 Thrift 服务 SaveServer 保存结果。
3. 使用一个消息队列 + 独立线程：
   * RPC 线程只负责接收请求；
   * 实际的 add / remove / match 在后台线程中顺序执行；
   * 避免多线程直接操作共享数据结构（`users`）。

**这是一个典型的：RPC 接入层 + 单线程逻辑处理 + 后台轮询匹配的架构。**

整体架构总结：
![整体架构总结示意图](20251225195115.png "整体架构总结示意图")

#### 2.3.2 具体实现

进入子目录 `match_system` 下，创建代码目录 `src`，进入 `src` 目录并执行 `thrift -r --gen cpp ../../thrift/match.thrift`，以根据接口文件 `match.thrift` 自动初始化匹配系统服务端的代码。

在当前 `src` 目录下，将会生成 `gen-cpp` 目录，存放匹配系统服务端的代码；我们将其重命名为 `match_server`，以区分之后的 `match_client`（即 match-client 端）。

以下考虑 match-server 端的实现。

由于需要单开一个线程用于不断进行玩家匹配操作的循环，因此需要使用生产者-消费者模型以完成该功能；生产者和消费者之间的通信可以使用消费队列来实现，而消费队列需要使用锁配合条件变量来实现。

同时，需要定义一个玩家池的类，来存放玩家。

在实现了匹配系统服务端的基础功能之后，我们考虑将匹配机制升级，可按照玩家分值差值进行玩家匹配。

目前我们采用单线程来处理匹配系统服务端的输入输出，因此根据 thrift 官方教程中提供的示例代码，将其升级改为多线程处理服务端。

接下来，我们将优化匹配系统逻辑：即若两个玩家分值差值不匹配而在一定时间范围内没有其他玩家进入匹配，这两名玩家可以“凑合”匹配到一起；需要实现随玩家的匹配秒数增加其匹配分值差值范围也随之增大的效果。

根据以上思路，补全 `match_server` 文件夹下的 `Match_server.skeleton.cpp` 文件。由于在数据存储系统客户端还需在此基础上添加逻辑，因此在这里暂不将完备代码展示；该完备代码请移步于《2.4 数据存储系统客户端实现》一节中查看。

将其移动到 `match_server` 文件夹的上一层目录 `src` 下，并将其重命名为 `main.cpp`。同时将 `match_server` 文件夹下的 `Match.cpp`、`match_types.cpp` 使用以下方式进行编译：
```bash
# 编译
g++ -c main.cpp
```

将编译生成的 `.o` 文件（`Match.o`、`match_types.o`）移动到上一层 `/thrift/match_system/src` 目录下，并以同样的方式编译该目录下的 `main.cpp` 文件，生成 `main.o` 文件。

最后，在当前 `/thrift/match_system/src` 目录下使用以下方式进行链接：
```bash
# 链接
g++ *.o -o main -lthrift    # 加入 thrift 的动态链接库
g++ *.o -o main -lthrift -pthread   # 加入 thrift 和 线程 的动态链接库
```

> 注意：C++ 语言的 `.cpp` 文件的编译需要先后进行编译和链接两步处理后，才可以变为可执行文件。

### 2.4 游戏进程客户端实现（Python3）

进入子目录 `game` 下，创建代码目录 `src`，进入 `src` 目录并执行 `thrift -r --gen py ../../thrift/match.thrift`，以根据接口文件 `match.thrift` 自动初始化游戏进程客户端的代码。

在当前 `src` 目录下，将会生成 `gen-py` 目录，存放游戏进程客户端的代码；与匹配系统服务端类似，我们将其重命名为 `match_client`。

新建客户端代码文件 `client.py`，根据 thrift 官方教程中提供的示例代码，补全该客户端业务代码：
```python
from match_client.match import Match
from match_client.match.ttypes import User

from thrift import Thrift
from thrift.transport import TSocket
from thrift.transport import TTransport
from thrift.protocol import TBinaryProtocol

from sys import stdin


def operate(op, user_id, username, score):
    # Make socket
    transport = TSocket.TSocket('127.0.0.1', 9090)

    # Buffering is critical. Raw sockets are very slow
    transport = TTransport.TBufferedTransport(transport)

    # Wrap in a protocol
    protocol = TBinaryProtocol.TBinaryProtocol(transport)

    # Create a client to use the protocol encoder
    client = Match.Client(protocol)

    # Connect!
    transport.open()

    user = User(user_id, username, score)

    if op == "add":
        client.add_user(user, "")
    elif op == "remove":
        client.remove_user(user, "")

    # Close!
    transport.close()


def main():
    for line in stdin:
        op, user_id, username, score = line.split(' ')
        operate(op, int(user_id), username, int(score))


if __name__ == "__main__":
        main()

```

> 注意：
> * 由于游戏进程客户端部署在 AC Terminal 本地上，因此该服务的 IP 地址为 `localhost`，即为 `127.0.0.1`。
> * 一般情况下，thrift 的端口通常为 `9090`。

### 2.5 数据存储系统客户端实现

> 拓展：
>
> 如何获取一个字符串的 md5 值？
>
> 使用如下方式可以获取一个字符串的 md5 值：
> ```bash
> md5sum
> ```
>
> 敲出 `md5sum` 后回车并输入待转换的字符串，回车后并按下 `Ctrl + d` 即可获取该字符串的 md5 值，以对该字符串进行加密。

在 `match_system/src` 目录下执行 `thrift -r --gen cpp ../../thrift/save.thrift`，以根据接口文件 `save.thrift` 自动初始化数据存储系统客户端的代码。

同样，在当前 `src` 目录下，将会生成 `gen-cpp` 目录，存放数据存储系统客户端的代码；与之前类似，我们将其重命名为 `save_client`。

进入到重命名为 `save_client` 的目录下，其中 `Save_server.skeleton.cpp` 为服务端的代码文件；由于此次项目只需实现客户端，而服务端直接调用已提供好的接口，因此需要将该文件删掉，以避免 C++ 中出现两个 `main` 函数。

在目录 `save_client` 下，对 `Save.cpp` 使用命令 `g++ -c Save.cpp` 进行编译，将编译生成文件 `Save.o` 移动到上层目录 `/thrift/match_system/src` 下。

根据 thrift 官方教程中提供的示例代码，补全 `match_system/src/main.cpp` 文件，同时需要注意头文件的引用：
```cpp
// This autogenerated skeleton file illustrates how to build a server.
// You should copy it to another filename to avoid overwriting it.

#include "match_server/Match.h" // 匹配服务接口（当前服务器提供）
#include "save_client/Save.h"   // 保存服务客户端（当前服务器调用别人的服务）
#include <thrift/concurrency/ThreadManager.h>
#include <thrift/concurrency/ThreadFactory.h>
#include <thrift/protocol/TBinaryProtocol.h>    // Thrift 核心组件：二进制协议（高效）
#include <thrift/server/TSimpleServer.h>
#include <thrift/server/TThreadedServer.h>  // Thrift 核心组件：多线程 RPC Server
#include <thrift/transport/TServerSocket.h>
#include <thrift/transport/TBufferTransports.h> // Thrift 核心组件：缓冲传输
#include <thrift/transport/TTransportUtils.h>
#include <thrift/transport/TSocket.h>
#include <thrift/TToString.h>

#include <iostream>
/* 标准 C++ 并发工具 */
/* 用于实现线程安全的任务队列 */
/* ************************************** */
#include <thread>
#include <mutex>
#include <condition_variable>
#include <queue>
/* ************************************** */
#include <vector>
#include <unistd.h>

using namespace ::apache::thrift;
using namespace ::apache::thrift::protocol;
using namespace ::apache::thrift::transport;
using namespace ::apache::thrift::server;

using namespace ::match_service;
using namespace ::save_service;
using namespace std;


// 表示一个操作任务
struct Task
{
    User user;  // Thrift 中定义的用户结构
    string type;
    // type:
    //  add: 加入匹配池
    //  remove: 从匹配池移除
};

// 一个线程安全的任务队列
/**
 * 设计意图：
 *  PRC 线程：往队列中塞任务
 *  后台线程：顺序取任务并处理
 *  避免多个 RPC 线程直接修改 Pool
 */
struct MessageQueue
{
    queue<Task> q;  // 存放待处理的任务
    mutex m;    // 互斥锁，保护 q
    condition_variable cv;  // 条件变量
}message_queue;


// 匹配核心逻辑
class Pool
{
    public:
        void save_result(int a, int b)
        {
            /**
             * 调用 SaveServer 保存匹配结果
             * 功能：
             *  输出匹配结果
             *  通过 Thrift 作为客户端调用远程 Save 服务
             *
             * 这是一个“Server 中嵌 Client”的经典用法
             */

            printf("Match Result: %d %d\n", a, b);


            std::shared_ptr<TTransport> socket(new TSocket("123.57.67.128", 9090)); // 连接 SaveServer 的 IP + 端口
            std::shared_ptr<TTransport> transport(new TBufferedTransport(socket));
            std::shared_ptr<TProtocol> protocol(new TBinaryProtocol(transport));
            SaveClient client(protocol);    // Thrift 自动生成的客户端

            try {
                transport->open();

                int res = client.save_data("acs_14641", "11cedf13", a, b);  // 保存匹配的两个用户 ID

                if (!res) puts("success");
                else puts("failed");

                transport->close();
            } catch (TException& tx) {
                cout << "ERROR: " << tx.what() << endl;
            }
        }

        bool check_match(uint32_t i, uint32_t j)
        {
            /**
             * 判断两个用户是否能匹配
             */

            auto a = users[i], b = users[j];

            // 匹配规则
            int dt = abs(a.score - b.score);    // 分数差 dt
            // 最大允许差 = 等待时间 * 50
            // 等待越久，匹配范围越宽
            int a_max_dif = wt[i] * 50;
            int b_max_dif = wt[j] * 50;

            return dt <= a_max_dif && dt <= b_max_dif;  // 双方都要“接受”这个分数差
        }

        void match()
        {
            /**
             * 核心匹配算法
             */
            // 所有用户等待时间 + 1
            // 每秒调用一次，动态放宽匹配条件
            for (uint32_t i = 0; i < wt.size(); i++)
                wt[i]++;    // 等待秒数 + 1

            while (users.size() > 1)
            {
                bool flag = true;
                // 两两尝试匹配
                // 暴力 O(n^2) 匹配（用户量小时可接受）
                for (uint32_t i = 0; i < users.size(); i++)
                {
                    for (uint32_t j = i + 1; j < users.size(); j++)
                    {
                        // 找到第一对可匹配用户就立即处理
                        if (check_match(i, j))
                        {
                            // 匹配成功后的处理
                            auto a = users[i], b = users[j];
                            // 从池中删除这两个用户
                            users.erase(users.begin() + j);
                            users.erase(users.begin() + i);
                            wt.erase(wt.begin() + j);
                            wt.erase(wt.begin() + i);
                            // 调用保存服务
                            save_result(a.id, b.id);
                            flag = false;
                            break;
                        }
                    }

                    // 然后重新开始下一轮匹配
                    if (!flag) break;
                }

                if (flag) break;
            }
        }

        void add(User user)
        {
            /**
             * 新用户加入
             */
            users.push_back(user);
            // 等待时间初始化为 0
            wt.push_back(0);
        }

        void remove(User user)
        {
            /**
             * 根据 user.id 查找并删除
             * 同步删除等待时间
             */
            for (uint32_t i = 0; i < users.size(); i++)
                if (users[i].id == user.id)
                {
                    users.erase(users.begin() + i);
                    wt.erase(wt.begin() + i);
                    break;
                }
        }

    private:
        // users[i] 和 wt[i] 一一对应
        // 等待越久，允许的分数差越大
        vector<User> users;
        vector<int> wt; // 等待时间，单位：s
}pool;


// Thrift RPC 接口实现
/**
 * RPC 线程不做任何业务处理
 * 只负责把请求转换为 Task 丢进队列
 * 极大降低并发复杂度
 */
class MatchHandler : virtual public MatchIf {   // RPC 接口真正的实现类
    public:
        MatchHandler() {
            // Your initialization goes here
        }

        int32_t add_user(const User& user, const std::string& info) {
            // Your implementation goes here
            printf("add_user\n");

            unique_lock<mutex> lck(message_queue.m);    // lock
            message_queue.q.push({user, "add"});    // push
            message_queue.cv.notify_all();  // notify

            return 0;
        }

        int32_t remove_user(const User& user, const std::string& info) {
            // Your implementation goes here
            printf("remove_user\n");

            unique_lock<mutex> lck(message_queue.m);    // lock
            message_queue.q.push({user, "remove"}); // push
            message_queue.cv.notify_all();  // notify

            return 0;
        }

};

// 多线程 Handler 工厂
/**
 * 作用：
 *  每一个 RPC 连接 / 线程
 *  创建一个独立的 MatchHandler
 */
class MatchCloneFactory : virtual public MatchIfFactory {
    public:
        ~MatchCloneFactory() override = default;
        MatchIf* getHandler(const ::apache::thrift::TConnectionInfo& connInfo) override
        {
            std::shared_ptr<TSocket> sock = std::dynamic_pointer_cast<TSocket>(connInfo.transport);
            /*cout << "Incoming connection\n";
            cout << "\tSocketInfo: "    << sock->getSocketInfo() << "\n";
            cout << "\tPeerHost: "      << sock->getPeerHost() << "\n";
            cout << "\tPeerAddress: "   << sock->getPeerAddress() << "\n";
            cout << "\tPeerPort: "      << sock->getPeerPort() << "\n";*/
            return new MatchHandler;    // 这是 TThreadedServer 的标准写法
        }
        void releaseHandler(MatchIf* handler) override {
            delete handler;
        }
};
// 后台逻辑线程
/**
 * 这是整个系统的“心脏”
 */
void consume_task()
{
    while (true)
    {
        unique_lock<mutex> lck(message_queue.m);
        if (message_queue.q.empty())
        {
            /**
             * 情况 1：队列为空
             *  没有新请求
             *  每秒尝试一次匹配
             *
             * 相当于一个定时匹配调度器
             */
            // message_queue.cv.wait(lck);
            lck.unlock();
            pool.match();
            sleep(1);
        }
        else
        {
            /**
             * 情况 2：有任务
             *  串行执行
             *  不会出现并发修改 users 的问题
             */
            auto task = message_queue.q.front();
            message_queue.q.pop();
            lck.unlock();

            if (task.type == "add") pool.add(task.user);
            else if (task.type == "remove") pool.remove(task.user);
        }
    }
}


int main(int argc, char **argv) {
    /**
     * 服务器启动
     */

    // 使用多线程 Thrift Server
    // 每个 RPC 请求一个线程
    TThreadedServer server(
            std::make_shared<MatchProcessorFactory>(std::make_shared<MatchCloneFactory>()),
            std::make_shared<TServerSocket>(9090),  // port
            std::make_shared<TBufferedTransportFactory>(),
            std::make_shared<TBinaryProtocolFactory>());


    cout << "Start Match Server" << endl;

    // 启动一个独立线程
    /**
     * 专门负责：
     *  add / remove
     *  match
     */
    thread matching_thread(consume_task);

    server.serve(); // 阻塞运行，监听 9090 端口
    return 0;
}

```

以同样的方式编译该目录下的 `main.cpp` 文件，生成 `main.o` 文件。

最后，在当前 `/thrift/match_system/src` 目录下使用以下方式进行链接：
```bash
# 链接
g++ *.o -o main -lthrift    # 加入 thrift 的动态链接库
g++ *.o -o main -lthrift -pthread   # 加入 thrift 和 线程 的动态链接库
```

> 注意：Linux 下的 C++ 代码需要区分自己编写的头文件和系统提供的头文件，自己编写的头文件在 `include` 时使用双引号 `""` 括起来，而系统提供的头文件在 `include` 时使用尖括号 `<>` 括起来。

由于数据存储系统节点是部署在远程服务器 myserver 上，因此在补全数据存储系统客户端的实现时，需要注意将 IP 地址更改为远程服务器 myserver 的 IP 地址。